{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options as ChromeOptions\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import datetime \n",
    "CHROME_DRIVER = './chromedriver'\n",
    "import time\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "def setup_driver(headless=True, driver_type=CHROME_DRIVER) -> webdriver:\n",
    "    options = ChromeOptions()\n",
    "    options.add_argument('--ignore-certificate-errors')\n",
    "    options.add_argument('--ignore-ssl-errors')\n",
    "    if headless:\n",
    "        options.add_argument('-headless')\n",
    "    driver = webdriver.Chrome(executable_path=driver_type, chrome_options=options)\n",
    "    return driver\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job = 'Software Enginner Intern'\n",
    "location = 'New York, NY'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_for_url(text):\n",
    "    return text.replace(' ','%20').replace(',','%2C')\n",
    "    \n",
    "\n",
    "def get_exact_link(job = None, location = None):\n",
    "    base_link = \"https://www.linkedin.com/jobs/search?keywords=\"\n",
    "    if job == None:\n",
    "        url = 'https://www.linkedin.com/jobs/search?keywords=software%20Engineer%20Intern&location='\n",
    "        \n",
    "    else:\n",
    "        url = base_link + filter_for_url(job)+'&location=' + filter_for_url(location)\n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_url = get_exact_link(job, location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_links(link):\n",
    "    #basic function to parse the soup\n",
    "    driver = setup_driver()\n",
    "    driver.get(link)\n",
    "    time.sleep(4)\n",
    "    soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "    driver.quit()\n",
    "\n",
    "    links = []\n",
    "    containers = soup.find_all('a',{'class':'base-card__full-link'})\n",
    "    for container in containers:\n",
    "        links.append(container.get('href'))\n",
    "    return links\n",
    "\n",
    "\n",
    "def get_soups(links):\n",
    "    driver = setup_driver()\n",
    "    soups =[]\n",
    "    for link in links:\n",
    "        driver.get(link)\n",
    "        time.sleep(4)\n",
    "        soups.append(BeautifulSoup(driver.page_source, \"html.parser\"))\n",
    "    driver.quit()\n",
    "    print(f'We parsed {str(len(soups))} job postings')\n",
    "    return soups\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = get_links(main_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soups = get_soups(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class job_posting_linkedIn(object):\n",
    "    def __init__(self):\n",
    "        self.job_title = None\n",
    "        self.company = None\n",
    "        self.original_link = None\n",
    "        self.job_location = None\n",
    "        self.seniority_level = None\n",
    "        self.employment_type = None\n",
    "        self.job_function = None\n",
    "        self.industries = None\n",
    "        self.linkedIn_link = None\n",
    "        self.posted_date = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_job_criteria_list(soup):\n",
    "    \n",
    "    try:\n",
    "        job_seniority = soup.find_all('span',{'class':'description__job-criteria-text description__job-criteria-text--criteria'})[0].text.strip()\n",
    "        job_type = soup.find_all('span',{'class':'description__job-criteria-text description__job-criteria-text--criteria'})[1].text.strip()\n",
    "        job_function = soup.find_all('span',{'class':'description__job-criteria-text description__job-criteria-text--criteria'})[2].text.strip()\n",
    "        job_industry = soup.find_all('span',{'class':'description__job-criteria-text description__job-criteria-text--criteria'})[3].text.strip()\n",
    "    except:\n",
    "        job_seniority, job_type, job_function, job_industry = None, None, None, None\n",
    "    return job_seniority, job_type, job_function, job_industry\n",
    "        \n",
    "    \n",
    "def parse_original_link(soup):\n",
    "    try:\n",
    "        link = soup.find('a',{'class':'apply-button apply-button--link top-card-layout__cta top-card-layout__cta--primary'}).get('href')\n",
    "    except:\n",
    "        link = None\n",
    "    return link\n",
    "\n",
    "\n",
    "def parse_posted_date(soup):\n",
    "    try:\n",
    "        date = soup.find('span',{'class':'posted-time-ago__text topcard__flavor--metadata'}).text.strip()\n",
    "    except:\n",
    "        date = None\n",
    "    return date\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "for soup in soups:\n",
    "    if soup.find('link',{'rel':'canonical'}):\n",
    "        job = job_posting_linkedIn()\n",
    "        \n",
    "        job.job_title = soup.find('h1',{'class':'top-card-layout__title topcard__title'}).text\n",
    "        job.linkedIn_link = soup.find('link',{'rel':'canonical'}).get('href')\n",
    "        job.original_link = parse_original_link(soup)\n",
    "       \n",
    "        job.posted_date = parse_posted_date(soup)\n",
    "\n",
    "        job.company = soup.find('a',{'class':'topcard__org-name-link topcard__flavor--black-link'}).text.strip()\n",
    "        job.job_location = soup.find('span',{'class':'topcard__flavor topcard__flavor--bullet'}).text.strip()\n",
    "        job.seniority_level, job.employment_type, job.job_function, job.industries = parse_job_criteria_list(soup)\n",
    "        df = df.append(job.__dict__, ignore_index=True)\n",
    "        \n",
    "df = df [['company', 'job_title',  'job_location', 'original_link', 'posted_date',  'employment_type', 'industries', 'job_function', 'linkedIn_link',  'seniority_level']]\n",
    "todays_date = f'{datetime.datetime.now():%d-%m-%Y-%H-%M}'\n",
    "csv_filename = \"linkedIn-\" + str(todays_date) +\".csv\"\n",
    "df.to_csv(os.path.expanduser(f'~/Downloads/{csv_filename}'))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
