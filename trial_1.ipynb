{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load imports\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options as ChromeOptions\n",
    "from datetime import datetime\n",
    "CHROME_DRIVER = './chromedriver'\n",
    "import time\n",
    "import pandas \n",
    "import os\n",
    "import re\n",
    "\n",
    "def setup_driver(headless=True, driver_type=CHROME_DRIVER) -> webdriver:\n",
    "    options = ChromeOptions()\n",
    "    options.add_argument('--ignore-certificate-errors')\n",
    "    options.add_argument('--ignore-ssl-errors')\n",
    "    if headless:\n",
    "        options.add_argument('-headless')\n",
    "    driver = webdriver.Chrome(executable_path=driver_type, chrome_options=options)\n",
    "    return driver\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_soup(link):\n",
    "    #basic function to parse the soup\n",
    "    driver = setup_driver()\n",
    "    driver.get(link)\n",
    "    time.sleep(8)\n",
    "    soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "    executing_query = \"document.getElementsByClassName('popover-x-button-close icl-CloseButton')[0].click()\"\n",
    "    #in case a pop up appears, it closes it\n",
    "    if soup.find('div',{'id':'popover-form-container'}):\n",
    "        driver.execute_script(executing_query)\n",
    "        soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "    print(driver.current_url)\n",
    "    driver.quit()\n",
    "    return soup\n",
    "\n",
    "\n",
    "def parse_all_pages(page):\n",
    "    #from the first page, it gets the links to all other pages..\n",
    "    page_links = []\n",
    "    blocks = page.find('ul',{'class':'pagination-list'}).find_all('li')\n",
    "    for block in blocks:\n",
    "        if block.find('a', href = True):\n",
    "            incomplete_link = block.find('a')['href']\n",
    "            page_links.append('https://www.indeed.com'+incomplete_link)\n",
    "            \n",
    "    pages = []\n",
    "    #stores the soup of all the pages\n",
    "    pages.append(page)\n",
    "    #appends the soup for the first page before getting into the loop\n",
    "    for link in set(page_links):\n",
    "        pages.append(get_soup(link))\n",
    "        #loops with all the links to other pages and stores their soups..\n",
    "    return pages\n",
    "\n",
    "def get_all_soups(pages):\n",
    "    soups = []\n",
    "    #stores the soups to each job postings, the soup from their specific \n",
    "    links_to_postings = []\n",
    "    #stores all the links to the specific job postings\n",
    "    for page in pages:\n",
    "        method_1 = page.find('div',{'class':'mosaic mosaic-provider-jobcards mosaic-provider-hydrated'})\n",
    "        method_2 = page.find('div',{'class':'jobsearch-SerpJobCard unifiedRow row result clickcard'})\n",
    "        #this takes care of the two different classes used in the html pages\n",
    "        if method_1:\n",
    "            container = method_1\n",
    "            boxes = container.find_all('a', href = True)\n",
    "        elif method_2:\n",
    "            container = method_2\n",
    "            boxes = container.find_all('a', href = True)\n",
    "        else:\n",
    "            return \"we don't have the job postings\"\n",
    "            # quits the method if the links are not found.\n",
    "            \n",
    "        if boxes: #proceeds only if links to different postings exists\n",
    "            for box in boxes:\n",
    "                first = box['href']\n",
    "                if '/rc/clk?jk' in first:\n",
    "                    link = first.replace('/rc/clk?','https://www.indeed.com/viewjob?')\n",
    "                    links_to_postings.append(link)\n",
    "                    #append all the links to the list\n",
    "    for link in set(links_to_postings):\n",
    "        soups.append(get_soup(link))\n",
    "        #get soups for unique job links parsed from different websites\n",
    "    print(f'we got {len(soups)} job postings')\n",
    "    return soups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class job_posting(object):\n",
    "    def __init__(self):\n",
    "        self.job_title = None\n",
    "        self.company = None\n",
    "        self.original_link = None\n",
    "        self.is_full_time = None\n",
    "        self.is_remote = None\n",
    "        self.job_location = None\n",
    "        self.description = None\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-736bf922cedc>:18: DeprecationWarning: use options instead of chrome_options\n",
      "  driver = webdriver.Chrome(executable_path=driver_type, chrome_options=options)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.indeed.com/jobs?q=%22Software+Engineer%22\n"
     ]
    }
   ],
   "source": [
    "page = get_soup('https://www.indeed.com/jobs?q=%22Software+Engineer%22&l=')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-736bf922cedc>:18: DeprecationWarning: use options instead of chrome_options\n",
      "  driver = webdriver.Chrome(executable_path=driver_type, chrome_options=options)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.indeed.com/jobs?q=%22Software+Engineer%22&start=10\n",
      "https://www.indeed.com/jobs?q=%22Software+Engineer%22&start=30\n",
      "https://www.indeed.com/jobs?q=%22Software+Engineer%22&start=20\n",
      "https://www.indeed.com/jobs?q=%22Software+Engineer%22&start=40\n"
     ]
    }
   ],
   "source": [
    "pages = parse_all_pages(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-736bf922cedc>:18: DeprecationWarning: use options instead of chrome_options\n",
      "  driver = webdriver.Chrome(executable_path=driver_type, chrome_options=options)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.indeed.com/viewjob?jk=5064b0d04f092d24&fccid=c060d0df634ace82&vjs=3\n",
      "https://www.indeed.com/viewjob?jk=be416ffb92528e8e&fccid=8bc01be85b97ce0d&vjs=3\n",
      "https://www.indeed.com/viewjob?jk=736425f950f1449f&fccid=ada833cd00ae27d8&vjs=3\n",
      "https://www.indeed.com/viewjob?jk=a4a0e9ccf8a052a8&fccid=66cdbe15c1ac4d49&vjs=3\n",
      "https://www.indeed.com/viewjob?jk=65aa93086ae9f208&fccid=dd616958bd9ddc12&vjs=3\n",
      "https://www.indeed.com/viewjob?jk=6c9db143ba6833a4&fccid=aaf3b433897ea465&vjs=3\n",
      "https://www.indeed.com/viewjob?jk=9b6cad7f40080b62&fccid=ba0b4ef452449c10&vjs=3\n",
      "https://www.indeed.com/viewjob?jk=c86732b141b38515&fccid=c007936ceb766fe5&vjs=3\n",
      "https://www.indeed.com/viewjob?jk=d4b43e0826a82778&fccid=4b5d257051285786&vjs=3\n",
      "https://www.indeed.com/viewjob?jk=e93f908c8eaf6bd7&fccid=e70a7b661388bb93&vjs=3\n",
      "https://www.indeed.com/viewjob?jk=5d418883c083d19d&fccid=9784ae78e9834539&vjs=3\n",
      "https://www.indeed.com/viewjob?jk=8fc22cb98176d55c&fccid=16a97ed26c75bf2d&vjs=3\n",
      "https://www.indeed.com/viewjob?jk=98e883979bea8ef0&fccid=3e3eaa6aedf690a3&vjs=3\n",
      "https://www.indeed.com/viewjob?jk=9882a391effc77b7&fccid=16a97ed26c75bf2d&vjs=3\n",
      "https://www.indeed.com/viewjob?jk=cb68e40c200d71d6&fccid=314d6d2bfc9df32c&vjs=3\n",
      "https://www.indeed.com/viewjob?jk=10ea647495b66b08&fccid=f766f8bfbc3effb7&vjs=3\n",
      "https://www.indeed.com/viewjob?jk=e2ac69e3df8da482&fccid=5b47cb6dc9bd7f35&vjs=3\n",
      "https://www.indeed.com/viewjob?jk=248caf8169be95ed&fccid=ae5bfc395c530fbc&vjs=3\n",
      "https://www.indeed.com/viewjob?jk=3c1814fe69710537&fccid=f89deb5a97c7738a&vjs=3\n",
      "https://www.indeed.com/viewjob?jk=d1ac7c3abb25c257&fccid=734cb5a01ee60f80&vjs=3\n",
      "https://www.indeed.com/viewjob?jk=6e60cfdfa9ed1dba&fccid=3e3eaa6aedf690a3&vjs=3\n",
      "https://www.indeed.com/viewjob?jk=0e0740e99356c723&fccid=31bebfb78bc1f0f1&vjs=3\n",
      "https://www.indeed.com/viewjob?jk=00901cbf8d49d554&fccid=fe2d21eef233e94a&vjs=3\n",
      "https://www.indeed.com/viewjob?jk=7bcc0e8542a54815&fccid=bee6abba453010ff&vjs=3\n",
      "https://www.indeed.com/viewjob?jk=b246045b00ff72ce&fccid=5bd99dfa21c8a490&vjs=3\n",
      "https://www.indeed.com/viewjob?jk=fcb7593ec9da4fcf&fccid=8b9bafd9d608c198&vjs=3\n",
      "https://www.indeed.com/viewjob?jk=ae3139c2282ce2b2&fccid=aef928e89977f7f0&vjs=3\n",
      "https://www.indeed.com/viewjob?jk=b1bc74ae6a65affd&fccid=fa0ca3b638673d62&vjs=3\n",
      "https://www.indeed.com/viewjob?jk=6bf3bcdbba573e4c&fccid=2ac0dbed95f0e3bf&vjs=3\n",
      "https://www.indeed.com/viewjob?jk=835c0973db3a626b&fccid=6bcbaf35af26e1a6&vjs=3\n",
      "https://www.indeed.com/viewjob?jk=1914d2bd592ea91d&fccid=cd9b55c1b610a1b1&vjs=3\n",
      "https://www.indeed.com/viewjob?jk=2ab912f23dd2ffbb&fccid=66403b30a2c0d89c&vjs=3\n",
      "https://www.indeed.com/viewjob?jk=8de169232ba54b8d&fccid=3e3eaa6aedf690a3&vjs=3\n",
      "https://www.indeed.com/viewjob?jk=97ac7dc76da3b0c1&fccid=1b50fcfb150b1b48&vjs=3\n",
      "https://www.indeed.com/viewjob?jk=cb0cec2741779a06&fccid=fc68da685e8aa986&vjs=3\n",
      "https://www.indeed.com/viewjob?jk=bf0ae9c135f9c38a&fccid=a2faf1301ac6ad4b&vjs=3\n",
      "https://www.indeed.com/viewjob?jk=76ddcf435e07a36e&fccid=c594c442f5397e7b&vjs=3\n",
      "we got 37 job postings\n"
     ]
    }
   ],
   "source": [
    "soups = get_all_soups(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_job_title(soup):\n",
    "    title = 'N/A'\n",
    "    title_text = soup.find('h1',{'class':'icl-u-xs-mb--xs icl-u-xs-mt--none jobsearch-JobInfoHeader-title'})\n",
    "    if title_text:\n",
    "        title = title_text.text.title()\n",
    "    return title    \n",
    "    \n",
    "    \n",
    "def parse_link(soup):\n",
    "    link = 'N/A'\n",
    "    link_text = soup.find('div',{'id':'originalJobLinkContainer'})\n",
    "    if link_text:\n",
    "        link = link_text.find('a')['href']\n",
    "    return link\n",
    "        \n",
    "        \n",
    "def parse_company_name(soup):\n",
    "    name = 'unknown'\n",
    "    text = soup.find('div',{'class':'jobsearch-InlineCompanyRating icl-u-xs-mt--xs jobsearch-DesktopStickyContainer-companyrating'})\n",
    "    if text:\n",
    "        name = re.sub('[0-9]','',text.text)\n",
    "    final = name.replace('reviews','').replace(',','').title()\n",
    "    return final\n",
    "\n",
    "\n",
    "def parse_working_time(soup):\n",
    "    soup_text = soup.text.lower()\n",
    "    if 'full time' in soup_text or 'full-time' in soup_text:\n",
    "        full_time = True\n",
    "    elif 'part time' in soup_text or 'part-time' in soup_text:\n",
    "        full_time = False\n",
    "    else:\n",
    "        full_time = 'N/A'\n",
    "    return full_time\n",
    "    \n",
    "    \n",
    "def parse_job_location(soup):\n",
    "    is_remote = 'N/A'\n",
    "    final = 'N/A'\n",
    "    entire_text = soup.find('div',{'class':'icl-u-xs-mt--xs icl-u-textColor--secondary jobsearch-JobInfoHeader-subtitle jobsearch-DesktopStickyContainer-subtitle'})\n",
    "    if entire_text:\n",
    "        company_name = soup.find('div',{'class':'jobsearch-InlineCompanyRating icl-u-xs-mt--xs jobsearch-DesktopStickyContainer-companyrating'}).text\n",
    "        final = entire_text.text.replace(company_name, '')\n",
    "    if 'remote' in final.lower():\n",
    "        final = final.lower().split('remote')[0].title()\n",
    "        is_remote = True\n",
    "    if final == '':\n",
    "        final = 'Remote'\n",
    "    return final , is_remote\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "for soup in soups:\n",
    "    job = job_posting()\n",
    "    job.job_title = parse_job_title(soup)\n",
    "    job.original_link = parse_link(soup)\n",
    "    job.company = parse_company_name(soup)\n",
    "    job.is_full_time = parse_working_time(soup)\n",
    "    job.job_location, job.is_remote = parse_job_location(soup)\n",
    "    df = df.append(job.__dict__, ignore_index=True)\n",
    "    df = df[['company', 'job_title', 'is_full_time', 'original_link', 'is_remote', 'job_location','description']]\n",
    "    todays_date = time.strftime(\"%d-%m-%Y\")\n",
    "    csv_filename = todays_date +\".csv\"\n",
    "    df.to_csv(os.path.expanduser(f'~/Downloads/{csv_filename}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
